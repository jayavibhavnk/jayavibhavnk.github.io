---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---
#### *Links may get disabled due to inactivity, please contact my on my email if you are unable to access them*

## Currently Researching

- Boosting LLM RAGs using graph neural networks.
- Image Search Engine using vector databases.
- Multimodal LLMs and agents.
- LLM fine-tuning.

## Research Experience

- Research Assistant under Professor and Head, Dr. N V Uma Reddy. (Oct 2022 - March 2023)
  - Worked on Gesture Recognition and Image Captioning.   
- Research Assistant under Professor, Dr Sreejith S. (June 2023 - July 2023)
  - Worked on fine-tuning Transformer models.    

## Research and Innovation

- Certificate of appreciation by New Horizon Research and Development Cell for publishing 3 Patents and participating in Government schemes and events for research and development, 2023.
- Project "TL;DWR" selected for government scheme, YUKTI (National Innovation Repository).  
- [Patent](https://patentscope.wipo.int/search/en/detail.jsf?docId=IN396260139&_cid=P12-LIFY7I-88034-1) selected for KAPILA government scheme for IP filing.

## Research Papers

### Visual Attention Based Image Captioning
Research paper accepted in IEEE, MRTM 2023.

**Abstract** - Image captioning is a process of automatically generating descriptive text captions for an image. It has attracted a great deal of attention due to its potential application in fields such as computer vision, NLP, assistive technologies and more. However, traditional image captioning methods often fail to capture the intricate semantics and lack contextual relevance. Lately, attention mechanisms are a viable solution to address these issues. The method that has been proposed leverages attention's capacity to create captions while also dynamically focusing on relevant image parts. This improves the model's contextual understanding of visual elements, allowing it to accurately describe intricate scenes and capture minute details. Our algorithm is evaluated against a reliable public benchmark, Flickr8K, and results (experimental) prove that our algorithm consistently outperforms the current approaches across various evaluation metrics. The results of the experiment are evaluated using BLEU, the most popular NLP metric used to measure caption quality.

Camera-ready paper: [paper](https://drive.google.com/drive/folders/1Izsw9qN3qCCGpmkaRNfa6Ti4ZDhCBWwr?usp=drive_link)

Project-link: [project](https://image-caption.streamlit.app/)

### Anti-Litter System using YOLOv5
Research paper accepted in IEEE, MRTM 2023.

**Abstract** - Littering is a serious environmental problem that degrades our surroundings' beauty and long-term viability. This paper suggests using the object detection algorithm YOLOv5 to prevent littering. The objective is to create an anti-litter system capable of identifying the action of dumping and tracking down the person responsible in real-time. The paper focuses on implementing YOLOv5 along with a background subtraction technique that tracks only the moving objects. When it is determined that the moving object is a human, a bounding box is formed, and any object that moves outside the box is found by measuring the distance between it and the human. It is acceptable to conclude that the item that separates from the person is trash. Once more examined by YOLOv5, if this object is found to be trash (such as bottles, covers, cans, etc.), the act of dumping is recognized. By the above-mentioned technique, the paper seeks to support ongoing efforts to create cleaner and more sustainable landscapes. It is now feasible to effectively detect and solve littering events, thereby fostering a cleaner and healthier ecology for everyone.

Camera-ready paper: [paper](https://drive.google.com/drive/folders/1Izsw9qN3qCCGpmkaRNfa6Ti4ZDhCBWwr?usp=drive_link)

### Educational content Unveiled: Classifier Models Discern AI-Generated Text’s Effects on Learning in Academic Contexts 
Research paper currently under review at Journal of AI in Education, 2023.

**Abstract** - In an era where artificial intelligence increasingly integrates itself into educational content creation, there arises a crucial necessity to discern between human-crafted and AI-generated material. Though the effect of AI-generated content in education is vast and prominent, the precise long-term effects are unknown. This research delves into the proficiency of five prominent language models—BERT, RoBERTa, DeBERTa, MPNET, and DistilBERT—in categorizing text as either AI-generated or originating from human intellect. Moreover, it investigates the utilization of these large language models for enhancing education by addressing the crucial question of how distinguishing AI-generated text can positively impact the educational landscape. Through a meticulous evaluation process, we assess the models’ capacity to unveil the subtle nuances that differentiate synthetic educational content, shedding light on the evolving landscape where artificial and human intelligence intersect. The findings of this study explain the ethical implications of AI and emphasize the challenges in transparently integrating machine-generated knowledge into educational frameworks, which also holds the potential to disrupt the traditional educational experience. 

Camera-ready paper: [paper](https://drive.google.com/drive/folders/1Izsw9qN3qCCGpmkaRNfa6Ti4ZDhCBWwr?usp=drive_link)

Links to models and datasets - [link](https://huggingface.co/jayavibhav)

Project link - [project](https://ai-text-classification.streamlit.app/)

*All models and datasets available on my huggingface account.*


## Patents

- Published Patent on GESTURE CONTROLLED INTERACTIVE MUSIC COMPOSITION SYSTEM WITH THE CAPABILITY OF AUTOMATIC COMPOSITION.
  <br>Publication Number - 202341020857, 2023.<br>
  [Link](https://patentscope.wipo.int/search/en/detail.jsf?docId=IN396260139&_cid=P12-LIFY7I-88034-1)
  
- Published Patent on REAL TIME HAND GESTURE RECOGNITION BASED ALTERNATE COMPUTER NAVIGATION USING FACE AUTHORISATION FOR REMOTE COMPUTER ACCESS.
  <br>Publication Number - 20234100745, 2023.<br>
  [Link](https://patentscope.wipo.int/search/en/detail.jsf?docId=IN393021434&_cid=P12-LIFYB1-89164-1)

